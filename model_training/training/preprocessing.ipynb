{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f191d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import torch \n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f18260",
   "metadata": {},
   "source": [
    "Vediamo se funziona import dei dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "919101b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\"\n",
    "\n",
    "TRAIN_PATH = f\"{DATA_DIR}/train_FD001.txt\"\n",
    "TEST_PATH  = f\"{DATA_DIR}/test_FD001.txt\"\n",
    "RUL_PATH   = f\"{DATA_DIR}/RUL_FD001.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433d309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = (\n",
    "    [\"id\", \"cycle\"] +\n",
    "    [\"setting1\", \"setting2\", \"setting3\"] +\n",
    "    [f\"sensor{i}\" for i in range(1, 22)]\n",
    ")\n",
    "\n",
    "train_df = pd.read_csv(\n",
    "    TRAIN_PATH,\n",
    "    sep=r\"\\s+\",\n",
    "    header=None,\n",
    "    names=column_names\n",
    ")\n",
    "\n",
    "test_df = pd.read_csv(\n",
    "    TEST_PATH,\n",
    "    sep=r\"\\s+\",\n",
    "    header=None,\n",
    "    names=column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ec7a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_rul = np.loadtxt(RUL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6ccdd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20631, 26)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30199b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor12</th>\n",
       "      <th>sensor13</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "      <th>sensor17</th>\n",
       "      <th>sensor18</th>\n",
       "      <th>sensor19</th>\n",
       "      <th>sensor20</th>\n",
       "      <th>sensor21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.42</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.86</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.19</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle  setting1  setting2  setting3  sensor1  sensor2  sensor3  \\\n",
       "0   1      1   -0.0007   -0.0004     100.0   518.67   641.82  1589.70   \n",
       "1   1      2    0.0019   -0.0003     100.0   518.67   642.15  1591.82   \n",
       "2   1      3   -0.0043    0.0003     100.0   518.67   642.35  1587.99   \n",
       "3   1      4    0.0007    0.0000     100.0   518.67   642.35  1582.79   \n",
       "4   1      5   -0.0019   -0.0002     100.0   518.67   642.37  1582.85   \n",
       "\n",
       "   sensor4  sensor5  ...  sensor12  sensor13  sensor14  sensor15  sensor16  \\\n",
       "0  1400.60    14.62  ...    521.66   2388.02   8138.62    8.4195      0.03   \n",
       "1  1403.14    14.62  ...    522.28   2388.07   8131.49    8.4318      0.03   \n",
       "2  1404.20    14.62  ...    522.42   2388.03   8133.23    8.4178      0.03   \n",
       "3  1401.87    14.62  ...    522.86   2388.08   8133.83    8.3682      0.03   \n",
       "4  1406.22    14.62  ...    522.19   2388.04   8133.80    8.4294      0.03   \n",
       "\n",
       "   sensor17  sensor18  sensor19  sensor20  sensor21  \n",
       "0       392      2388     100.0     39.06   23.4190  \n",
       "1       392      2388     100.0     39.00   23.4236  \n",
       "2       390      2388     100.0     38.95   23.3442  \n",
       "3       392      2388     100.0     38.88   23.3739  \n",
       "4       393      2388     100.0     38.90   23.4044  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23ac1098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_uninformative_columns(df, cols=None):\n",
    "    \"\"\"\n",
    "    Rimuove le colonne non utilizzate per il modello.\n",
    "    Restituisce anche la lista delle colonne effettivamente droppate.\n",
    "    \"\"\"\n",
    "    if cols is None:\n",
    "        cols = [\n",
    "            'setting1', 'setting2', 'setting3',\n",
    "            'sensor1', 'sensor5', 'sensor6',\n",
    "            'sensor10', 'sensor16', 'sensor18', 'sensor19'\n",
    "        ]\n",
    "\n",
    "    df_clean = df.copy()\n",
    "    to_drop = [c for c in cols if c in df_clean.columns]\n",
    "    df_clean.drop(columns=to_drop, inplace=True)\n",
    "\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28107c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  cycle  sensor2  sensor3  sensor4  sensor7  sensor8  sensor9  sensor11  \\\n",
      "0   1      1   641.82  1589.70  1400.60   554.36  2388.06  9046.19     47.47   \n",
      "1   1      2   642.15  1591.82  1403.14   553.75  2388.04  9044.07     47.49   \n",
      "2   1      3   642.35  1587.99  1404.20   554.26  2388.08  9052.94     47.27   \n",
      "3   1      4   642.35  1582.79  1401.87   554.45  2388.11  9049.48     47.13   \n",
      "4   1      5   642.37  1582.85  1406.22   554.00  2388.06  9055.15     47.28   \n",
      "\n",
      "   sensor12  sensor13  sensor14  sensor15  sensor17  sensor20  sensor21  \n",
      "0    521.66   2388.02   8138.62    8.4195       392     39.06   23.4190  \n",
      "1    522.28   2388.07   8131.49    8.4318       392     39.00   23.4236  \n",
      "2    522.42   2388.03   8133.23    8.4178       390     38.95   23.3442  \n",
      "3    522.86   2388.08   8133.83    8.3682       392     38.88   23.3739  \n",
      "4    522.19   2388.04   8133.80    8.4294       393     38.90   23.4044  \n"
     ]
    }
   ],
   "source": [
    "train_df = drop_uninformative_columns(train_df)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "030533a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rul(df, id_col=\"id\", cycle_col=\"cycle\"):\n",
    "    \"\"\"\n",
    "    Calcola la RUL per ogni riga:\n",
    "        RUL = max_cycle(id) - cycle\n",
    "    \"\"\"\n",
    "    df_rul = df.copy()\n",
    "    max_cycles = df_rul.groupby(id_col)[cycle_col].max()\n",
    "    df_rul[\"RUL\"] = df_rul[id_col].map(max_cycles) - df_rul[cycle_col]\n",
    "    return df_rul\n",
    "\n",
    "\n",
    "def rul_cap(df, max_rul=125):\n",
    "    \"\"\"\n",
    "    Applica un limite superiore alla RUL (C-MAPSS richiede capping).\n",
    "    \"\"\"\n",
    "    if \"RUL\" not in df.columns:\n",
    "        raise ValueError(\"RUL must be computed before capping.\")\n",
    "\n",
    "    df_capped = df.copy()\n",
    "    df_capped[\"RUL\"] = df_capped[\"RUL\"].clip(upper=max_rul)\n",
    "    return df_capped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94408b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  cycle  sensor2  sensor3  sensor4  sensor7  sensor8  sensor9  sensor11  \\\n",
      "0   1      1   641.82  1589.70  1400.60   554.36  2388.06  9046.19     47.47   \n",
      "1   1      2   642.15  1591.82  1403.14   553.75  2388.04  9044.07     47.49   \n",
      "2   1      3   642.35  1587.99  1404.20   554.26  2388.08  9052.94     47.27   \n",
      "3   1      4   642.35  1582.79  1401.87   554.45  2388.11  9049.48     47.13   \n",
      "4   1      5   642.37  1582.85  1406.22   554.00  2388.06  9055.15     47.28   \n",
      "\n",
      "   sensor12  sensor13  sensor14  sensor15  sensor17  sensor20  sensor21  RUL  \n",
      "0    521.66   2388.02   8138.62    8.4195       392     39.06   23.4190  191  \n",
      "1    522.28   2388.07   8131.49    8.4318       392     39.00   23.4236  190  \n",
      "2    522.42   2388.03   8133.23    8.4178       390     38.95   23.3442  189  \n",
      "3    522.86   2388.08   8133.83    8.3682       392     38.88   23.3739  188  \n",
      "4    522.19   2388.04   8133.80    8.4294       393     38.90   23.4044  187  \n"
     ]
    }
   ],
   "source": [
    "train_df = compute_rul(train_df)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "252e18ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  cycle  sensor2  sensor3  sensor4  sensor7  sensor8  sensor9  sensor11  \\\n",
      "0   1      1   641.82  1589.70  1400.60   554.36  2388.06  9046.19     47.47   \n",
      "1   1      2   642.15  1591.82  1403.14   553.75  2388.04  9044.07     47.49   \n",
      "2   1      3   642.35  1587.99  1404.20   554.26  2388.08  9052.94     47.27   \n",
      "3   1      4   642.35  1582.79  1401.87   554.45  2388.11  9049.48     47.13   \n",
      "4   1      5   642.37  1582.85  1406.22   554.00  2388.06  9055.15     47.28   \n",
      "\n",
      "   sensor12  sensor13  sensor14  sensor15  sensor17  sensor20  sensor21  RUL  \n",
      "0    521.66   2388.02   8138.62    8.4195       392     39.06   23.4190  125  \n",
      "1    522.28   2388.07   8131.49    8.4318       392     39.00   23.4236  125  \n",
      "2    522.42   2388.03   8133.23    8.4178       390     38.95   23.3442  125  \n",
      "3    522.86   2388.08   8133.83    8.3682       392     38.88   23.3739  125  \n",
      "4    522.19   2388.04   8133.80    8.4294       393     38.90   23.4044  125  \n"
     ]
    }
   ],
   "source": [
    "train_df = rul_cap(train_df)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b17e039",
   "metadata": {},
   "source": [
    "Ora dobbiamo creare le SlidingWindows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3f0083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlidingWindowGenerator:\n",
    "    def __init__(self, window_size, feature_cols, target_col, id_col = \"id\", stride = 1):\n",
    "        self.window_size = window_size\n",
    "        self.feature_cols = feature_cols\n",
    "        self.target_col = target_col\n",
    "        self.id_col = id_col\n",
    "        self.stride = stride\n",
    "    \n",
    "    def transform(self, df):\n",
    "\n",
    "        X_list, y_list = [], []\n",
    "\n",
    "        for id, group in df.groupby(self.id_col):\n",
    "            x = group[self.feature_cols].values\n",
    "            y = group[self.target_col].values\n",
    "            n_cycles = len(group)\n",
    "\n",
    "            if n_cycles < self.window_size:\n",
    "                continue\n",
    "\n",
    "            indices = range(0, n_cycles - self.window_size + 1, self.stride)\n",
    "\n",
    "            for start in indices:\n",
    "                end = start + self.window_size\n",
    "                X_list.append(x[start:end])\n",
    "                y_list.append(y[end - 1])\n",
    "            \n",
    "        X_out = np.stack(X_list) if X_list else np.empty((0, self.window_size, len(self.feature_cols)))\n",
    "        y_out = np.array(y_list) if y_list else np.empty((0,))\n",
    "\n",
    "        return X_out, y_out \n",
    "\n",
    "    def get_params(self):\n",
    "        return {\"window_size\" : self.window_size, \"stride\" : self.stride, \"num_features\" : len(self.feature_cols)}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98e2d26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = list(train_df.columns)\n",
    "feature_cols.remove(\"RUL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcae5847",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = SlidingWindowGenerator(\n",
    "    window_size=30,\n",
    "    feature_cols=feature_cols,\n",
    "    target_col=\"RUL\",\n",
    "    id_col=\"id\",\n",
    "    stride=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0d80c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "engine_ids = train_df[\"id\"].unique()\n",
    "\n",
    "train_ids, val_ids = train_test_split(\n",
    "    engine_ids, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04061feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_split = train_df[train_df[\"id\"].isin(train_ids)]\n",
    "val_df_split   = train_df[train_df[\"id\"].isin(val_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2c6b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = sw.transform(train_df_split)\n",
    "X_val, y_val     = sw.transform(val_df_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8532146a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(set(train_df_split[\"id\"]).intersection(set(val_df_split[\"id\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41416387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "N_train, T, F = X_train.shape\n",
    "\n",
    "X_train_2d = X_train.reshape(-1, F)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_2d = scaler.fit_transform(X_train_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11cce500",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_val = X_val.shape[0]\n",
    "\n",
    "X_val_2d = X_val.reshape(-1, F)\n",
    "X_val_scaled_2d = scaler.transform(X_val_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0d68b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train_scaled_2d.reshape(N_train, T, F)\n",
    "X_val_scaled   = X_val_scaled_2d.reshape(N_val, T, F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f082162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.15889802e-12 -1.93775717e-14  2.63704262e-10 -2.96275799e-12\n",
      "  1.44102249e-11 -6.16730512e-11  1.30607379e-08  6.15406677e-11\n",
      " -3.20857642e-11  1.31248689e-10  9.71778784e-09 -3.41024245e-12\n",
      "  1.61841452e-11 -2.66398341e-14  6.44508735e-13 -1.65518013e-11]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled.mean(axis=(0,1)))\n",
    "print(X_train_scaled.std(axis=(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bb908b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.27015694 -0.04828585  0.03123073  0.01615084  0.03238681 -0.02322893\n",
      "  0.02322153 -0.0304183   0.0239359  -0.02182792  0.02071528 -0.03449098\n",
      "  0.0187379   0.01636852 -0.047899   -0.03201162]\n"
     ]
    }
   ],
   "source": [
    "print(X_val_scaled.mean(axis=(0,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3405b6",
   "metadata": {},
   "source": [
    "Qui facciamo un test per vedere che tutto funzioni correttamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2f54f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from preprocessing.data_clean import (\n",
    "    drop_uninformative_columns,\n",
    "    compute_rul,\n",
    "    rul_cap\n",
    ")\n",
    "\n",
    "from preprocessing.SlidingWindowClass import SlidingWindowGenerator\n",
    "from preprocessing.scaling import TimeSeriesScaler\n",
    "\n",
    "from models.GNN_Transformer import st_gnn_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b73ced1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\"\n",
    "\n",
    "column_names = (\n",
    "    [\"id\", \"cycle\"] +\n",
    "    [\"setting1\", \"setting2\", \"setting3\"] +\n",
    "    [f\"sensor{i}\" for i in range(1, 22)]\n",
    ")\n",
    "\n",
    "train_df = pd.read_csv(\n",
    "    f\"{DATA_DIR}/train_FD001.txt\",\n",
    "    sep=r\"\\s+\",\n",
    "    header=None,\n",
    "    names=column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16c32d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = drop_uninformative_columns(train_df)\n",
    "train_df = compute_rul(train_df)\n",
    "train_df = rul_cap(train_df, max_rul=125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85fcbdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "engine_ids = train_df[\"id\"].unique()\n",
    "\n",
    "train_ids, val_ids = train_test_split(\n",
    "    engine_ids,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_df_split = train_df[train_df[\"id\"].isin(train_ids)]\n",
    "val_df_split   = train_df[train_df[\"id\"].isin(val_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4367bb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [c for c in train_df.columns if \"sensor\" in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ec45a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = SlidingWindowGenerator(\n",
    "    window_size=30,\n",
    "    feature_cols=feature_cols,\n",
    "    target_col=\"RUL\"\n",
    ")\n",
    "\n",
    "X_train, y_train = sw.transform(train_df_split)\n",
    "X_val, y_val     = sw.transform(val_df_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f1aa851",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = TimeSeriesScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled   = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4a3f80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14241, 30, 14)\n",
      "(3490, 30, 14)\n",
      "[ 2.63704262e-10 -2.96275799e-12  1.44102249e-11 -6.16730512e-11\n",
      "  1.30607379e-08  6.15406677e-11 -3.20857642e-11  1.31248689e-10\n",
      "  9.71778784e-09 -3.41024245e-12  1.61841452e-11 -2.66398341e-14\n",
      "  6.44508735e-13 -1.65518013e-11]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled.shape)\n",
    "print(X_val_scaled.shape)\n",
    "\n",
    "print(X_train_scaled.mean(axis=(0,1)))\n",
    "print(X_train_scaled.std(axis=(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b78d889c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models.GNN_Transformer.st_gnn_transformer import STGNNTransformer\n",
    "from models.GNN_Transformer.losses import RMSELoss\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -----------------------\n",
    "# CONFIGURAZIONE MODELLO\n",
    "# -----------------------\n",
    "num_sensors = X_train_scaled.shape[2]\n",
    "\n",
    "config = {\n",
    "    \"num_nodes\": num_sensors,\n",
    "    \"input_features\": 1,\n",
    "    \"gnn_hidden_dim\": 128,\n",
    "    \"trans_d_model\": 256,\n",
    "    \"trans_nhead\": 1,\n",
    "    \"trans_layers\": 2,\n",
    "    \"dropout_prob\": 0\n",
    "}\n",
    "\n",
    "# -----------------------\n",
    "# MATRICE DI ADIACENZA\n",
    "# -----------------------\n",
    "init_adj_matrix = torch.ones(\n",
    "    config[\"num_nodes\"],\n",
    "    config[\"num_nodes\"]\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# MODELLO E LOSS\n",
    "# -----------------------\n",
    "model = STGNNTransformer(config, init_adj_matrix).to(device)\n",
    "criterion = RMSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d13824f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [01/30] | Train RMSE: 85.812 | Val RMSE: 82.506\n",
      "Epoch [02/30] | Train RMSE: 71.135 | Val RMSE: 61.854\n",
      "Epoch [03/30] | Train RMSE: 47.322 | Val RMSE: 71.598\n",
      "Epoch [04/30] | Train RMSE: 27.715 | Val RMSE: 77.627\n",
      "Epoch [05/30] | Train RMSE: 24.643 | Val RMSE: 81.737\n",
      "Epoch [06/30] | Train RMSE: 23.175 | Val RMSE: 24.124\n",
      "Epoch [07/30] | Train RMSE: 22.743 | Val RMSE: 26.077\n",
      "Epoch [08/30] | Train RMSE: 22.538 | Val RMSE: 72.783\n",
      "Epoch [09/30] | Train RMSE: 22.154 | Val RMSE: 101.294\n",
      "Epoch [10/30] | Train RMSE: 23.690 | Val RMSE: 346.950\n",
      "Epoch [11/30] | Train RMSE: 22.954 | Val RMSE: 132.447\n",
      "Epoch [12/30] | Train RMSE: 21.024 | Val RMSE: 719.548\n",
      "Epoch [13/30] | Train RMSE: 19.095 | Val RMSE: 447.883\n",
      "Epoch [14/30] | Train RMSE: 18.242 | Val RMSE: 1199.787\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m xb \u001b[38;5;241m=\u001b[39m xb\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     61\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 62\u001b[0m preds \u001b[38;5;241m=\u001b[39m model(xb)\n\u001b[1;32m     63\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(preds, yb)\n\u001b[1;32m     65\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/Python_Project/model_training/training/models/GNN_Transformer/st_gnn_transformer.py:70\u001b[0m, in \u001b[0;36mSTGNNTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m gcn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgcn(x, A)\n\u001b[1;32m     69\u001b[0m seq \u001b[38;5;241m=\u001b[39m gcn_out\u001b[38;5;241m.\u001b[39mreshape(B, T, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 70\u001b[0m seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(seq)\n\u001b[1;32m     71\u001b[0m seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoder(seq)\n\u001b[1;32m     73\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_encoder(seq)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/linear.py:134\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    131\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    Runs the forward pass.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# IPERPARAMETRI\n",
    "# =========================\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 64\n",
    "LR = 1e-3\n",
    "\n",
    "# =========================\n",
    "# DATASET & DATALOADER\n",
    "# =========================\n",
    "X_train_t = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_val_t = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "y_val_t = torch.tensor(y_val, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(X_train_t, y_train_t),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    TensorDataset(X_val_t, y_val_t),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# OPTIMIZER\n",
    "# =========================\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# =========================\n",
    "# TRACKING LOSS\n",
    "# =========================\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# =========================\n",
    "# TRAINING LOOP\n",
    "# =========================\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    # ---- TRAIN ----\n",
    "    model.train()\n",
    "    train_loss_epoch = 0.0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        # (B, T, F) → (B, T, N, 1)\n",
    "        xb = xb.unsqueeze(-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss_epoch += loss.item() * xb.size(0)\n",
    "\n",
    "    train_loss_epoch /= len(train_loader.dataset)\n",
    "    train_losses.append(train_loss_epoch)\n",
    "\n",
    "\n",
    "    # ---- VALIDATION ----\n",
    "    model.eval()\n",
    "    val_loss_epoch = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            xb = xb.unsqueeze(-1)\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "\n",
    "            val_loss_epoch += loss.item() * xb.size(0)\n",
    "\n",
    "    val_loss_epoch /= len(val_loader.dataset)\n",
    "    val_losses.append(val_loss_epoch)\n",
    "\n",
    "    # ---- LOG ----\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1:02d}/{EPOCHS}] | \"\n",
    "        f\"Train RMSE: {train_loss_epoch:.3f} | \"\n",
    "        f\"Val RMSE: {val_loss_epoch:.3f}\"\n",
    "    )\n",
    "\n",
    "# =========================\n",
    "# PLOT CURVE\n",
    "# =========================\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_losses, label=\"Train RMSE\")\n",
    "plt.plot(val_losses, label=\"Validation RMSE\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.title(\"Training vs Validation RMSE\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
